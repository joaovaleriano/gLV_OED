{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import combinations\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from analysis import *\n",
    "from inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)] \n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_species = [3 5]\n",
      "avg_samp_dt = [3.  1.5]\n",
      "env_noise = 0.1\n",
      "meas_noise_list = [0.1]\n",
      "n_params_seeds = 10\n"
     ]
    }
   ],
   "source": [
    "datapath = \"../experiment_outputs/test_perturb_env_noise0.1\"\n",
    "log = h5py.File(f\"{datapath}/data_generation_log.h5\", \"r\")\n",
    "\n",
    "print(f\"n_species = {log.attrs['n_species']}\")\n",
    "print(f\"avg_samp_dt = {log.attrs['avg_samp_dt']}\")\n",
    "print(f\"env_noise = {log.attrs['env_noise']}\")\n",
    "print(f\"meas_noise_list = {log.attrs['meas_noise_list']}\")\n",
    "print(f\"n_params_seeds = {log.attrs['n_params_seeds']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sp = 3\n",
    "avg_samp_dt = 3.\n",
    "env_noise = log.attrs[\"env_noise\"]\n",
    "meas_noise = 0.1\n",
    "n_params_seeds = log.attrs['n_params_seeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles = []\n",
    "metadatafiles = []\n",
    "\n",
    "params_seeds = [i.split(\"param_seed\")[1] for i in os.listdir(f\"{datapath}/{n_sp}_sp\")]\n",
    "for p in params_seeds:\n",
    "    datafiles.append(f\"{datapath}/{n_sp}_sp/param_seed{p}/meas_noise{meas_noise}/t_samp{avg_samp_dt}/dataset{n_sp}_sp{p}_env_noise{env_noise}.csv\")\n",
    "    metadatafiles.append(f\"{datapath}/{n_sp}_sp/param_seed{p}/meas_noise{meas_noise}/t_samp{avg_samp_dt}/metadata{n_sp}_sp{p}_env_noise{env_noise}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafiles[-1], index_col=0)\n",
    "metatext = open(metadatafiles[-1], \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of sampling points: [11 21]\n",
      "Average sampling intervals: [3.  1.5]\n",
      "Number of initial conditions: 5\n",
      "Number of repetitions: 1\n",
      "Environmental noise: 0.1\n",
      "Amounts of measurement noise: [0.1]\n"
     ]
    }
   ],
   "source": [
    "metadict = get_meta(metatext)\n",
    "\n",
    "print(f\"Numbers of sampling points: {metadict['n_tpoints']}\")\n",
    "print(f\"Average sampling intervals: {metadict['avg_dt'].round(3)}\")\n",
    "print(f\"Number of initial conditions: {metadict['n_init_cond']}\")\n",
    "print(f\"Number of repetitions: {metadict['repetitions']}\")\n",
    "print(f\"Environmental noise: {metadict['env_noise']}\")\n",
    "print(f\"Amounts of measurement noise: {metadict['meas_noise']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_es_score(true_aij, inferred_aij) -> float:\n",
    "    \"\"\"GRANT'S edited version to calculate ED score\n",
    "\n",
    "    Calculate the ecological direction (EDₙ) score (n := number of species in ecosystem).\n",
    "\n",
    "    Parameters\n",
    "    ===============\n",
    "    truth: ndarray(axis0=species_names, axis1=species_names), the ecosystem coefficient matrix used to generate data\n",
    "    inferred: ndarray(axis0=species_names, axis1=species_names), the inferred ecosystem coefficient matrix\n",
    "    Returns\n",
    "    ===============\n",
    "    ES_score: float\n",
    "    \"\"\"\n",
    "\n",
    "    truth = pd.DataFrame(true_aij).copy()\n",
    "    inferred = pd.DataFrame(inferred_aij).copy()\n",
    "\n",
    "    # consider inferred coefficients\n",
    "    mask = inferred != 0\n",
    "\n",
    "    # compare sign: agreement when == -2 or +2, disagreement when 0\n",
    "    nonzero_sign = np.sign(inferred)[mask] + np.sign(truth)[mask]\n",
    "    corr_sign = (np.abs(nonzero_sign) == 2).sum().sum()\n",
    "    opposite_sign = (np.abs(nonzero_sign) == 0).sum().sum()\n",
    "\n",
    "    # count incorrect non-zero coefficients\n",
    "    wrong_nz = (truth[mask] == 0).sum().sum()\n",
    "\n",
    "    # combine\n",
    "    unscaled_score = corr_sign - opposite_sign\n",
    "\n",
    "    # scale by theoretical extrema\n",
    "    truth_nz_counts = (truth != 0).sum().sum()\n",
    "    truth_z_counts = len(truth.index) ** 2 - truth_nz_counts\n",
    "    theoretical_min = -truth_nz_counts\n",
    "    theoretical_max = truth_nz_counts\n",
    "\n",
    "    ES_score = (unscaled_score - theoretical_min) / (theoretical_max - theoretical_min)\n",
    "\n",
    "    return ES_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.65it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.40it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.92it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.03it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.19it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.89it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.94it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.13it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.82it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.60it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.73it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.63it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Infer and score\n",
    "\n",
    "param_columns = [f\"r{i}\" for i in range(1, n_sp+1)] + \\\n",
    "                [f\"A{i},{j}\" for i in range(1, n_sp+1) for j in range(1, n_sp+1)]\n",
    "\n",
    "cols = [\"n_init_cond\"] + list(df.columns[1:4]) + param_columns + [\"MSPD\", \"CSR\", \"ES\"]\n",
    "\n",
    "for avg_samp_dt in log.attrs[\"avg_samp_dt\"]:\n",
    "    for meas_noise in log.attrs[\"meas_noise_list\"]:\n",
    "        datafiles = []\n",
    "\n",
    "        params_seeds = [i.split(\"param_seed\")[1] for i in os.listdir(f\"{datapath}/{n_sp}_sp\")]\n",
    "        for p in params_seeds:\n",
    "            datafiles.append(f\"{datapath}/{n_sp}_sp/param_seed{p}/meas_noise{meas_noise}/t_samp{avg_samp_dt}/dataset{n_sp}_sp{p}_env_noise{env_noise}.csv\")\n",
    "\n",
    "        for file_idx in range(len(datafiles)):\n",
    "            datafile = datafiles[file_idx]\n",
    "\n",
    "            df = pd.read_csv(datafile, index_col=0)\n",
    "            \n",
    "            infer_out = pd.DataFrame(columns=cols)\n",
    "\n",
    "            pd.options.mode.chained_assignment = None\n",
    "\n",
    "            p = metadict[\"parameters\"]\n",
    "            r = p[:n_sp]\n",
    "            A = p[n_sp:].reshape((n_sp,n_sp))\n",
    "\n",
    "            for i in tqdm(range(len(df.init_cond_idx.unique()))):\n",
    "                combs = list(combinations(df.init_cond_idx.unique(), i+1))\n",
    "                np.random.shuffle(combs)\n",
    "                for comb in combs[:100]:\n",
    "                    df_comb = df[df.init_cond_idx.isin(comb)]\n",
    "                    r_est, A_est = fit_ridge_cv(df_comb)\n",
    "                    p_est = np.concatenate((r_est, A_est.flatten()))\n",
    "                    MSPD = ((p-p_est)**2).mean()\n",
    "                    CSR = (np.sign(A_est)==np.sign(A)).mean()\n",
    "                    ES = calculate_es_score(A, A_est)\n",
    "                    infer_out.loc[len(infer_out)] = [i+1, comb, avg_samp_dt, meas_noise] + list(p_est) + [MSPD, CSR, ES]\n",
    "\n",
    "            infer_out.to_csv(datafile.split('dataset')[0]+\"/inference\"+datafile.split(\"dataset\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f66c9cb52b40e00ac570727ccd8b1767a1d502bed964675cbccc34495792c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
