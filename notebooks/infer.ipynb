{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import combinations\n",
    "import h5py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from analysis import *\n",
    "from inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def natural_sort(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower() \n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)] \n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_species = [10]\n",
      "avg_samp_dt = [3.  1.5 1. ]\n",
      "env_noise = 0.1\n",
      "meas_noise_list = [0.1]\n",
      "n_params_seeds = 5\n"
     ]
    }
   ],
   "source": [
    "datapath = \"../experiment_outputs/growth_rep_env_noise0.1\"\n",
    "log = h5py.File(f\"{datapath}/data_generation_log.h5\", \"r\")\n",
    "\n",
    "print(f\"n_species = {log.attrs['n_species']}\")\n",
    "print(f\"avg_samp_dt = {log.attrs['avg_samp_dt']}\")\n",
    "print(f\"env_noise = {log.attrs['env_noise']}\")\n",
    "print(f\"meas_noise_list = {log.attrs['meas_noise_list']}\")\n",
    "print(f\"n_params_seeds = {log.attrs['n_params_seeds']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(datapath, n_sp, env_noise, meas_noise, avg_samp_dt, filetype=\"dataset\", ext=\"csv\"):\n",
    "    params_seeds = [i.split(\"param_seed\")[1] for i in os.listdir(f\"{datapath}/{n_sp}_sp\")]\n",
    "\n",
    "    datafiles = []\n",
    "\n",
    "    for p in params_seeds:\n",
    "        datafiles.append(f\"{datapath}/{n_sp}_sp/param_seed{p}/meas_noise{meas_noise}/t_samp{avg_samp_dt}/{filetype}{n_sp}_sp{p}_env_noise{env_noise}.{ext}\")\n",
    "    return datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of sampling points: [11 21 31]\n",
      "Average sampling intervals: [3.  1.5 1. ]\n",
      "Number of initial conditions: 5\n",
      "Number of repetitions: 20\n",
      "Environmental noise: 0.1\n",
      "Amounts of measurement noise: [0.1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numbers of sampling points: {log.attrs['n_samples']}\")\n",
    "print(f\"Average sampling intervals: {log.attrs['avg_samp_dt'].round(3)}\")\n",
    "print(f\"Number of initial conditions: {log.attrs['n_init_cond']}\")\n",
    "print(f\"Number of repetitions: {log.attrs['repetitions']}\")\n",
    "print(f\"Environmental noise: {log.attrs['env_noise']}\")\n",
    "print(f\"Amounts of measurement noise: {log.attrs['meas_noise_list']}\")\n",
    "\n",
    "env_noise = log.attrs['env_noise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_es_score(true_aij, inferred_aij) -> float:\n",
    "    \"\"\"GRANT'S edited version to calculate ED score\n",
    "\n",
    "    Calculate the ecological direction (EDâ‚™) score (n := number of species in ecosystem).\n",
    "\n",
    "    Parameters\n",
    "    ===============\n",
    "    truth: ndarray(axis0=species_names, axis1=species_names), the ecosystem coefficient matrix used to generate data\n",
    "    inferred: ndarray(axis0=species_names, axis1=species_names), the inferred ecosystem coefficient matrix\n",
    "    Returns\n",
    "    ===============\n",
    "    ES_score: float\n",
    "    \"\"\"\n",
    "\n",
    "    truth = pd.DataFrame(true_aij).copy()\n",
    "    inferred = pd.DataFrame(inferred_aij).copy()\n",
    "\n",
    "    # consider inferred coefficients\n",
    "    mask = inferred != 0\n",
    "\n",
    "    # compare sign: agreement when == -2 or +2, disagreement when 0\n",
    "    nonzero_sign = np.sign(inferred)[mask] + np.sign(truth)[mask]\n",
    "    corr_sign = (np.abs(nonzero_sign) == 2).sum().sum()\n",
    "    opposite_sign = (np.abs(nonzero_sign) == 0).sum().sum()\n",
    "\n",
    "    # count incorrect non-zero coefficients\n",
    "    wrong_nz = (truth[mask] == 0).sum().sum()\n",
    "\n",
    "    # combine\n",
    "    unscaled_score = corr_sign - opposite_sign\n",
    "\n",
    "    # scale by theoretical extrema\n",
    "    truth_nz_counts = (truth != 0).sum().sum()\n",
    "    truth_z_counts = len(truth.index) ** 2 - truth_nz_counts\n",
    "    theoretical_min = -truth_nz_counts\n",
    "    theoretical_max = truth_nz_counts\n",
    "\n",
    "    ES_score = (unscaled_score - theoretical_min) / (theoretical_max - theoretical_min)\n",
    "\n",
    "    return ES_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>init_cond_idx</th>\n",
       "      <th>t_samp_dist_idx</th>\n",
       "      <th>measurement_noise</th>\n",
       "      <th>replicate</th>\n",
       "      <th>time</th>\n",
       "      <th>dt</th>\n",
       "      <th>sp1</th>\n",
       "      <th>sp2</th>\n",
       "      <th>sp3</th>\n",
       "      <th>sp4</th>\n",
       "      <th>sp5</th>\n",
       "      <th>sp6</th>\n",
       "      <th>sp7</th>\n",
       "      <th>sp8</th>\n",
       "      <th>sp9</th>\n",
       "      <th>sp10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.024119</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>0.013260</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>0.021861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>0.026880</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.021556</td>\n",
       "      <td>0.037407</td>\n",
       "      <td>0.035245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.092971</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>0.107373</td>\n",
       "      <td>0.052974</td>\n",
       "      <td>0.052923</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>0.061179</td>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>0.035552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141262</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>0.204517</td>\n",
       "      <td>0.081370</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>0.076802</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.059759</td>\n",
       "      <td>0.037350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.225501</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.275799</td>\n",
       "      <td>0.141263</td>\n",
       "      <td>0.148743</td>\n",
       "      <td>0.038659</td>\n",
       "      <td>0.115082</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.065005</td>\n",
       "      <td>0.041596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363928</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.442523</td>\n",
       "      <td>0.256032</td>\n",
       "      <td>0.301295</td>\n",
       "      <td>0.141893</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>0.159031</td>\n",
       "      <td>0.055561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400128</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.408842</td>\n",
       "      <td>0.264956</td>\n",
       "      <td>0.347910</td>\n",
       "      <td>0.140371</td>\n",
       "      <td>0.031851</td>\n",
       "      <td>0.112886</td>\n",
       "      <td>0.179235</td>\n",
       "      <td>0.067466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.406289</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.555427</td>\n",
       "      <td>0.217759</td>\n",
       "      <td>0.284295</td>\n",
       "      <td>0.167293</td>\n",
       "      <td>0.032265</td>\n",
       "      <td>0.086926</td>\n",
       "      <td>0.157854</td>\n",
       "      <td>0.066552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.429302</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.495994</td>\n",
       "      <td>0.275562</td>\n",
       "      <td>0.335936</td>\n",
       "      <td>0.144133</td>\n",
       "      <td>0.033661</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>0.172065</td>\n",
       "      <td>0.059546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>99.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.367384</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.431686</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.322360</td>\n",
       "      <td>0.127698</td>\n",
       "      <td>0.033054</td>\n",
       "      <td>0.101184</td>\n",
       "      <td>0.179899</td>\n",
       "      <td>0.063577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3100 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset  init_cond_idx  t_samp_dist_idx  measurement_noise  replicate  \\\n",
       "0         0.0            0.0              2.0                0.1        0.0   \n",
       "1         0.0            0.0              2.0                0.1        0.0   \n",
       "2         0.0            0.0              2.0                0.1        0.0   \n",
       "3         0.0            0.0              2.0                0.1        0.0   \n",
       "4         0.0            0.0              2.0                0.1        0.0   \n",
       "...       ...            ...              ...                ...        ...   \n",
       "3095     99.0            4.0              2.0                0.1       19.0   \n",
       "3096     99.0            4.0              2.0                0.1       19.0   \n",
       "3097     99.0            4.0              2.0                0.1       19.0   \n",
       "3098     99.0            4.0              2.0                0.1       19.0   \n",
       "3099     99.0            4.0              2.0                0.1       19.0   \n",
       "\n",
       "      time   dt       sp1       sp2       sp3       sp4       sp5       sp6  \\\n",
       "0      0.0  1.0  0.026325  0.005365  0.023963  0.013102  0.024119  0.015263   \n",
       "1      1.0  1.0  0.041217  0.007788  0.053101  0.026880  0.030246  0.023798   \n",
       "2      2.0  1.0  0.092971  0.011043  0.107373  0.052974  0.052923  0.024794   \n",
       "3      3.0  1.0  0.141262  0.015159  0.204517  0.081370  0.103300  0.031650   \n",
       "4      4.0  1.0  0.225501  0.017266  0.275799  0.141263  0.148743  0.038659   \n",
       "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "3095  26.0  1.0  0.363928  0.005563  0.442523  0.256032  0.301295  0.141893   \n",
       "3096  27.0  1.0  0.400128  0.005218  0.408842  0.264956  0.347910  0.140371   \n",
       "3097  28.0  1.0  0.406289  0.004069  0.555427  0.217759  0.284295  0.167293   \n",
       "3098  29.0  1.0  0.429302  0.004914  0.495994  0.275562  0.335936  0.144133   \n",
       "3099  30.0  NaN  0.367384  0.003250  0.431686  0.244000  0.322360  0.127698   \n",
       "\n",
       "           sp7       sp8       sp9      sp10  \n",
       "0     0.013260  0.023745  0.024693  0.021861  \n",
       "1     0.027603  0.021556  0.037407  0.035245  \n",
       "2     0.061179  0.025030  0.058830  0.035552  \n",
       "3     0.076802  0.027765  0.059759  0.037350  \n",
       "4     0.115082  0.040491  0.065005  0.041596  \n",
       "...        ...       ...       ...       ...  \n",
       "3095  0.034704  0.092784  0.159031  0.055561  \n",
       "3096  0.031851  0.112886  0.179235  0.067466  \n",
       "3097  0.032265  0.086926  0.157854  0.066552  \n",
       "3098  0.033661  0.093785  0.172065  0.059546  \n",
       "3099  0.033054  0.101184  0.179899  0.063577  \n",
       "\n",
       "[3100 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.12it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.55it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.60it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.29it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.15it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.25it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.00it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Infer and score\n",
    "\n",
    "for n_sp in log.attrs[\"n_species\"]:\n",
    "    for avg_samp_dt in log.attrs[\"avg_samp_dt\"]:\n",
    "        for meas_noise in log.attrs[\"meas_noise_list\"]:\n",
    "            datafiles = get_files(datapath, n_sp, env_noise, meas_noise, avg_samp_dt)\n",
    "            metadatafiles = get_files(datapath, n_sp, env_noise, meas_noise, avg_samp_dt, \"metadata\", \"txt\")\n",
    "\n",
    "            for file_idx in range(len(datafiles)):\n",
    "                datafile = datafiles[file_idx]\n",
    "                metadatafile = metadatafiles[file_idx]\n",
    "                metadict = get_meta(open(metadatafile, \"r\").read().split(\"\\n\"))\n",
    "                \n",
    "                df = pd.read_csv(datafile, index_col=0)\n",
    "                \n",
    "                param_columns = [f\"r{i}\" for i in range(1, n_sp+1)] + \\\n",
    "                [f\"A{i},{j}\" for i in range(1, n_sp+1) for j in range(1, n_sp+1)]\n",
    "                cols = [\"n_init_cond\"] + list(df.columns[1:4]) + param_columns + [\"MSPD\", \"CSR\", \"ES\"]\n",
    "\n",
    "                infer_out = pd.DataFrame(columns=cols)\n",
    "\n",
    "                pd.options.mode.chained_assignment = None\n",
    "                \n",
    "                p = metadict[\"parameters\"]\n",
    "                r = p[:n_sp]\n",
    "                A = p[n_sp:].reshape((n_sp,n_sp))\n",
    "\n",
    "                for i in tqdm(range(len(df.init_cond_idx.unique()))):\n",
    "                    combs = list(combinations(df.init_cond_idx.unique(), i+1))\n",
    "                    np.random.shuffle(combs)\n",
    "                    for comb in combs[:100]:\n",
    "                        df_comb = df[df.init_cond_idx.isin(comb)]\n",
    "                        r_est, A_est = fit_ridge_cv(df_comb)\n",
    "                        p_est = np.concatenate((r_est, A_est.flatten()))\n",
    "                        MSPD = ((p-p_est)**2).mean()\n",
    "                        CSR = (np.sign(A_est)==np.sign(A)).mean()\n",
    "                        ES = calculate_es_score(A, A_est)\n",
    "                        infer_out.loc[len(infer_out)] = [i+1, comb, avg_samp_dt, meas_noise] + list(p_est) + [MSPD, CSR, ES]\n",
    "\n",
    "                infer_out.to_csv(datafile.split('dataset')[0]+\"/inference\"+datafile.split(\"dataset\")[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f66c9cb52b40e00ac570727ccd8b1767a1d502bed964675cbccc34495792c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
